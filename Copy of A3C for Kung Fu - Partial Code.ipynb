{"cells":[{"cell_type":"markdown","source":["# A3C for Kung Fu"],"metadata":{"id":"dIo6Zkp7U1Hq"}},{"cell_type":"markdown","source":["## Part 0 - Installing the required packages and importing the libraries"],"metadata":{"id":"pz8ogVxGVB6b"}},{"cell_type":"markdown","source":["### Installing Gymnasium"],"metadata":{"id":"CqN2IEX1VKzi"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"dbnq3XpoKa_7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707342832976,"user_tz":300,"elapsed":21653,"user":{"displayName":"Robert Zheng","userId":"02836817127272693658"}},"outputId":"eb146c43-8879-4da3-ba53-cc2a2ff87e53"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.29.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.23.5)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.9.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n","Requirement already satisfied: gymnasium[accept-rom-license,atari] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (1.23.5)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (4.9.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (0.0.4)\n","Requirement already satisfied: shimmy[atari]<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (0.2.1)\n","Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in /usr/local/lib/python3.10/dist-packages (from gymnasium[accept-rom-license,atari]) (0.4.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (8.1.7)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (4.66.1)\n","Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (0.6.1)\n","Requirement already satisfied: ale-py~=0.8.1 in /usr/local/lib/python3.10/dist-packages (from shimmy[atari]<1.0,>=0.1.0->gymnasium[accept-rom-license,atari]) (0.8.1)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0->gymnasium[accept-rom-license,atari]) (6.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license,atari]) (2024.2.2)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","swig is already the newest version (4.0.2-1ubuntu1).\n","0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n","Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (1.23.5)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.9.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (0.0.4)\n","Requirement already satisfied: box2d-py==2.3.5 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.3.5)\n","Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.5.2)\n","Requirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.2.0)\n"]}],"source":["!pip install gymnasium\n","!pip install \"gymnasium[atari, accept-rom-license]\"\n","!apt-get install -y swig\n","!pip install gymnasium[box2d]"]},{"cell_type":"markdown","source":["### Importing the libraries"],"metadata":{"id":"BrsNHNQqVZLK"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"Ho_25-9_9qnu","executionInfo":{"status":"ok","timestamp":1707342836257,"user_tz":300,"elapsed":3284,"user":{"displayName":"Robert Zheng","userId":"02836817127272693658"}}},"outputs":[],"source":["import cv2\n","import math\n","import random\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.multiprocessing as mp\n","import torch.distributions as distributions\n","from torch.distributions import Categorical\n","import gymnasium as gym\n","from gymnasium import ObservationWrapper\n","from gymnasium.spaces import Box"]},{"cell_type":"markdown","source":["## Part 1 - Building the AI"],"metadata":{"id":"VF6EFSGUVlk2"}},{"cell_type":"markdown","source":["### Creating the architecture of the Neural Network"],"metadata":{"id":"qyNc8cxbZCYP"}},{"cell_type":"code","source":["class Network(nn.Module):\n","\n","  def __init__(self, action_size):\n","    super(Network, self).__init__() #call the method from the nn Module\n","    self.conv1 = torch.nn.Conv2d(in_channels = 4, out_channels = 32, kernel_size = (3,3), stride = 2)\n","    #4 grayscale frames for the kungfu environment as the input channels\n","    self.conv2 = torch.nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = (3,3), stride = 2)\n","    self.conv3 = torch.nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = (3,3), stride = 2)\n","    self.flatten = torch.nn.Flatten() #create a flattening layer within an object\n","    self.fc1 = torch.nn.Linear(512, 128) #512 inputs, 128 outputs for fully connected layer\n","    self.fc2a = torch.nn.Linear(128, action_size)\n","    self.fc2s = torch.nn.Linear(128, 1)\n","\n","  def forward(self, state):\n","    x = self.conv1(state)\n","    x = F.relu(x)\n","    x = self.conv2(x)\n","    x = F.relu(x)\n","    x = self.conv3(x)\n","    x = F.relu(x)\n","    x = self.flatten(x)\n","    x = self.fc1(x)\n","    x = F.relu(x)\n","    action_values = self.fc2a(x)\n","    state_value = self.fc2s(x)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RsQr6OqmO9OU","executionInfo":{"status":"ok","timestamp":1707342836257,"user_tz":300,"elapsed":4,"user":{"displayName":"Robert Zheng","userId":"02836817127272693658"}},"outputId":"5fe141a8-1fe8-4b8e-df71-fb93e44dc1f1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}]},{"cell_type":"markdown","source":["## Part 2 - Training the AI"],"metadata":{"id":"eF5bETqbZbCG"}},{"cell_type":"markdown","source":["### Setting up the environment"],"metadata":{"id":"3C2ydyKLZgaK"}},{"cell_type":"code","source":["class PreprocessAtari(ObservationWrapper):\n","\n","  def __init__(self, env, height = 42, width = 42, crop = lambda img: img, dim_order = 'pytorch', color = False, n_frames = 4):\n","    super(PreprocessAtari, self).__init__(env)\n","    self.img_size = (height, width)\n","    self.crop = crop\n","    self.dim_order = dim_order\n","    self.color = color\n","    self.frame_stack = n_frames\n","    n_channels = 3 * n_frames if color else n_frames\n","    obs_shape = {'tensorflow': (height, width, n_channels), 'pytorch': (n_channels, height, width)}[dim_order]\n","    self.observation_space = Box(0.0, 1.0, obs_shape)\n","    self.frames = np.zeros(obs_shape, dtype = np.float32)\n","\n","  def reset(self):\n","    self.frames = np.zeros_like(self.frames)\n","    obs, info = self.env.reset()\n","    self.update_buffer(obs)\n","    return self.frames, info\n","\n","  def observation(self, img):\n","    img = self.crop(img)\n","    img = cv2.resize(img, self.img_size)\n","    if not self.color:\n","      if len(img.shape) == 3 and img.shape[2] == 3:\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    img = img.astype('float32') / 255.\n","    if self.color:\n","      self.frames = np.roll(self.frames, shift = -3, axis = 0)\n","    else:\n","      self.frames = np.roll(self.frames, shift = -1, axis = 0)\n","    if self.color:\n","      self.frames[-3:] = img\n","    else:\n","      self.frames[-1] = img\n","    return self.frames\n","\n","  def update_buffer(self, obs):\n","    self.frames = self.observation(obs)\n","\n","def make_env():\n","  env = gym.make(\"KungFuMasterDeterministic-v0\", render_mode = 'rgb_array')\n","  env = PreprocessAtari(env, height = 42, width = 42, crop = lambda img: img, dim_order = 'pytorch', color = False, n_frames = 4)\n","  return env\n","\n","env = make_env()\n","\n","state_shape = env.observation_space.shape\n","number_actions = env.action_space.n\n","print(\"Observation shape:\", state_shape)\n","print(\"Number actions:\", number_actions)\n","print(\"Action names:\", env.env.env.get_action_meanings())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gF756uIhRVcK","executionInfo":{"status":"ok","timestamp":1707342837317,"user_tz":300,"elapsed":1063,"user":{"displayName":"Robert Zheng","userId":"02836817127272693658"}},"outputId":"c9e9d6cb-f942-4339-f067-41885241f615"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gymnasium/envs/registration.py:513: DeprecationWarning: \u001b[33mWARN: The environment KungFuMasterDeterministic-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n","  logger.deprecation(\n"]},{"output_type":"stream","name":"stdout","text":["Observation shape: (4, 42, 42)\n","Number actions: 14\n","Action names: ['NOOP', 'UP', 'RIGHT', 'LEFT', 'DOWN', 'DOWNRIGHT', 'DOWNLEFT', 'RIGHTFIRE', 'LEFTFIRE', 'DOWNFIRE', 'UPRIGHTFIRE', 'UPLEFTFIRE', 'DOWNRIGHTFIRE', 'DOWNLEFTFIRE']\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_action_meanings to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_action_meanings` for environment variables or `env.get_wrapper_attr('get_action_meanings')` that will search the reminding wrappers.\u001b[0m\n","  logger.warn(\n"]}]},{"cell_type":"markdown","source":["### Initializing the hyperparameters"],"metadata":{"id":"YgRlooBmC1hr"}},{"cell_type":"code","source":["learning_rate = 1e-4\n","discount_factor = 0.99\n","number_environments = 10 #wow ten environments running in parrallel\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x3Q8HngeTRZv","executionInfo":{"status":"ok","timestamp":1707342837317,"user_tz":300,"elapsed":2,"user":{"displayName":"Robert Zheng","userId":"02836817127272693658"}},"outputId":"94ce8363-330c-4030-9ebe-514bea2d259c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}]},{"cell_type":"markdown","source":["### Implementing the A3C class"],"metadata":{"id":"Gg_LmSs9IoTX"}},{"cell_type":"code","source":["class Agent():\n","\n","  def __init__(self, action_size):\n","    self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    self.action_size = action_size\n","    self.network = Network(action_size).to(self.device)\n","    self.optimizer = torch.optim.Adam(self.network.parameters(), lr = learning_rate)\n","\n","  def act(self, state): #implementing softmax!\n","    if state.ndim == 3:\n","      state = [state]\n","    state = torch.tensor(state, dtype = torch.float32, device = self.device)\n","    # make the state a torch tensor\n","    action_values, _ = self.network(state)\n","    policy = F.softmax(action_values, dim = -1)\n","    #torch tensor policy, detatched, moved to CPU and converted to a numpy array\n","    return np.array([np.random.choice(len(p), p = p) for p in policy.detach().cpu().numpy()])\n","\n","  def step(self, state, action, reward, next_state, done):\n","    batch_size = state.shape[0]\n","    #convert to torch tensors\n","    state = torch.tensor(state, dtype = torch.float32, device = self.device)\n","    next_state = torch.tensor(next_state, dtype = torch.float32, device = self.device)\n","    reward = torch.tensor(reward, dtype = torch.float32, device = self.device)\n","    done = torch.tensor(done, dtype = torch.bool, device = self.device).to(dtype = torch.float32)\n","    action_values, state_values = self.network(state)\n","    _, next_state_value = self.network(next_state)\n","    target_state_value = reward + discount_factor * next_state_value * (1-done)\n","    #advantage feature incoming\n","    advantage = target_state_value = state_value\n","    #critic part here we are\n","    probs = F.softmax(action_values, dim = -1)\n","    logprobs = F.log_softmax(action_values, dim = -1)\n","    entropy = -torch.sum(probs * logprobs, acis = -1)\n","    batch_idx = np.arange(batch_size)\n","    logp_actions = logprobs[batch_idx, action]\n","    actor_loss = -(logp_actions * advantage.detach()).mean() - 0.001 * entropy.mean()\n","    critic_loss = F.mse_loss(target_state_value.detach(), state_value)\n","    total_loss = actor_loss + critic_loss\n","    self.optimizer.zero_grad() #reset before backpropagation\n","    total_loss.backward()\n","    self.optimizer.step() #go back forward\n"],"metadata":{"id":"FqFk6Pawaxku","executionInfo":{"status":"ok","timestamp":1707342837317,"user_tz":300,"elapsed":1,"user":{"displayName":"Robert Zheng","userId":"02836817127272693658"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["### Initializing the A3C agent"],"metadata":{"id":"7RnRukHDKFJ0"}},{"cell_type":"code","source":["agent = Agent(number_actions)"],"metadata":{"id":"Z69h7jUNl3Vt","executionInfo":{"status":"ok","timestamp":1707342838560,"user_tz":300,"elapsed":1244,"user":{"displayName":"Robert Zheng","userId":"02836817127272693658"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["### Evaluating our A3C agent on a single episode"],"metadata":{"id":"oB5SpmoKP0aK"}},{"cell_type":"code","source":["def evaluate(agent, env, n_episodes = 1):\n","  episodes_rewards = []\n","  for _ in range(n_episodes):\n","    state, _ = env.reset()\n","    total_reward = 0\n","    while True:\n","      action = agent.act(state)\n","      state, reward, done, info, _ = env.step(action[0])\n","      total_reward += reward\n","      if done:\n","        break\n","    episodes_rewards.append(total_reward)\n","  return episodes_rewards"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"71ZBpsoiZBsi","executionInfo":{"status":"ok","timestamp":1707342838561,"user_tz":300,"elapsed":2,"user":{"displayName":"Robert Zheng","userId":"02836817127272693658"}},"outputId":"0e57aaaf-5fe7-47be-f94c-25909f852d4f"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}]},{"cell_type":"markdown","source":["### Testing multiple agents on multiple environments at the same time"],"metadata":{"id":"jVSqiyjiQeMd"}},{"cell_type":"code","source":["class EnvBatch:\n","\n","  def __init__(self, n_envs = 10):\n","    self.envs = [make_env() for _ in range(n_envs)]\n","\n","  def reset(self):\n","    _states = []\n","    for env in self.envs:\n","      _states.append(env.reset()[0])\n","    return np.array(_states)\n","\n","  def step(self, actions):\n","    next_states, rewards, dones, infos, _ = map(np.array,zip(*[env.step(a) for env, a in zip(self.envs, actions)]))\n","    #check if any environment is finished\n","    for i in range(len(self.envs)):\n","      if dones[i]:\n","        next_states[i] = self.envs[i].reset()[0]\n","    return next_states, rewards, dones, infos"],"metadata":{"id":"OWdueNRkbr1s","executionInfo":{"status":"ok","timestamp":1707342838561,"user_tz":300,"elapsed":2,"user":{"displayName":"Robert Zheng","userId":"02836817127272693658"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### Training the A3C agent"],"metadata":{"id":"69WZWB4oRx1P"}},{"cell_type":"code","source":["import tqdm\n","\n","env_batch = EnvBatch(number_environments)\n","batch_states = env_batch.reset()\n","\n","with tqdm.trange(0, 3001) as progress_bar:\n","  #i is iteration\n","  for i in progress_bar:\n","    batch_actions = agent.act(batch_states)\n","    batch_next_states, batch_rewards, batch_dones, _ = env_batch.steo(batch_actions)\n","    batch_rewards *= 0.01\n","    agent.step(batch_states, batch_actions, batch_rewards, batch_next_states, batch_dones)\n","    batch_states = batch_next_states\n","    if i & 1000 == 0:\n","      print(\"Average agent reward: \", np.mean(evaluate(agent, env, n_episodes = 10)))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"id":"3fxJXs99eJM-","executionInfo":{"status":"error","timestamp":1707342843385,"user_tz":300,"elapsed":4826,"user":{"displayName":"Robert Zheng","userId":"02836817127272693658"}},"outputId":"961476be-bc47-4d43-de5c-bb95da0e9a90"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gymnasium/envs/registration.py:513: DeprecationWarning: \u001b[33mWARN: The environment KungFuMasterDeterministic-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n","  logger.deprecation(\n","  0%|          | 0/3001 [00:00<?, ?it/s]\n"]},{"output_type":"error","ename":"TypeError","evalue":"cannot unpack non-iterable NoneType object","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-efde13ab6a62>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m#i is iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mbatch_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mbatch_next_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mbatch_rewards\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-9e6ff07b8dc1>\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# make the state a torch tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0maction_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#torch tensor policy, detatched, moved to CPU and converted to a numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"]}]},{"cell_type":"markdown","source":["## Part 3 - Visualizing the results"],"metadata":{"id":"7kG_YR9YdmUM"}},{"cell_type":"code","source":["import glob\n","import io\n","import base64\n","import imageio\n","from IPython.display import HTML, display\n","from gymnasium.wrappers.monitoring.video_recorder import VideoRecorder\n","\n","def show_video_of_model(agent, env):\n","  state, _ = env.reset()\n","  done = False\n","  frames = []\n","  while not done:\n","    frame = env.render()\n","    frames.append(frame)\n","    action = agent.act(state)\n","    state, reward, done, _, _ = env.step(action[0])\n","  env.close()\n","  imageio.mimsave('video.mp4', frames, fps=30)\n","\n","show_video_of_model(agent, env)\n","\n","def show_video():\n","    mp4list = glob.glob('*.mp4')\n","    if len(mp4list) > 0:\n","        mp4 = mp4list[0]\n","        video = io.open(mp4, 'r+b').read()\n","        encoded = base64.b64encode(video)\n","        display(HTML(data='''<video alt=\"test\" autoplay\n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n","             </video>'''.format(encoded.decode('ascii'))))\n","    else:\n","        print(\"Could not find video\")\n","\n","show_video()"],"metadata":{"id":"UGkTuO6DxZ6B","executionInfo":{"status":"aborted","timestamp":1707342843386,"user_tz":300,"elapsed":3,"user":{"displayName":"Robert Zheng","userId":"02836817127272693658"}}},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"19mlgPA6Zj97xML3Mj-8sb0mg8t5W0nmm","timestamp":1696937661479}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}